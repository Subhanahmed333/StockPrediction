{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcd8d7e",
   "metadata": {},
   "source": [
    "# üìà Stock Price Prediction & Sentiment Analysis - Complete Workflow\n",
    "\n",
    "This notebook demonstrates the complete end-to-end workflow for stock price prediction using machine learning and sentiment analysis.\n",
    "\n",
    "## üéØ What You'll Learn:\n",
    "- üìä Data collection from financial APIs (yfinance)\n",
    "- üîß Feature engineering with technical indicators\n",
    "- ü§ñ Training multiple ML models (Random Forest, Gradient Boosting, XGBoost)\n",
    "- üìà Making price predictions\n",
    "- üí¨ Sentiment analysis on financial text\n",
    "- üìâ Visualizing results with interactive charts\n",
    "\n",
    "**Author:** Stock Prediction System  \n",
    "**Date:** November 2025  \n",
    "**Version:** 1.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7277a8d",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9095a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "# Custom modules\n",
    "from data_collector import StockDataCollector\n",
    "from sentiment_analyzer import SentimentAnalyzer\n",
    "from ml_models import StockPricePredictor, ModelComparison\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a8dc0",
   "metadata": {},
   "source": [
    "## üìä 2. Data Collection\n",
    "\n",
    "Let's collect historical stock data using yfinance. We'll use Bitcoin (BTC-USD) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4aba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collector\n",
    "collector = StockDataCollector()\n",
    "\n",
    "# Configuration\n",
    "SYMBOL = \"BTC-USD\"  # You can change this to any stock: AAPL, TSLA, ETH-USD, etc.\n",
    "INTERVAL = \"1h\"     # 1h for hourly, 1d for daily\n",
    "PERIOD = \"3mo\"      # 7d, 1mo, 3mo, 6mo, 1y\n",
    "\n",
    "print(f\"üì• Collecting data for {SYMBOL}...\")\n",
    "print(f\"   Interval: {INTERVAL}\")\n",
    "print(f\"   Period: {PERIOD}\")\n",
    "print()\n",
    "\n",
    "# Collect data\n",
    "df = collector.get_stock_data(SYMBOL, interval=INTERVAL, period=PERIOD)\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    print(f\"‚úÖ Successfully collected {len(df)} data points\")\n",
    "    print(f\"   Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "    print()\n",
    "    print(\"First few rows:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"‚ùå Failed to collect data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b7523",
   "metadata": {},
   "source": [
    "## üîß 3. Feature Engineering\n",
    "\n",
    "Now let's add technical indicators to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af13e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical indicators\n",
    "print(\"üîß Engineering features...\")\n",
    "df_features = collector.add_technical_indicators(df)\n",
    "\n",
    "print(f\"‚úÖ Added {len(df_features.columns) - len(df.columns)} new features\")\n",
    "print()\n",
    "print(\"Available features:\")\n",
    "print(df_features.columns.tolist())\n",
    "print()\n",
    "print(\"Data with features:\")\n",
    "display(df_features.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc275c12",
   "metadata": {},
   "source": [
    "## üìà 4. Data Visualization\n",
    "\n",
    "Let's visualize the stock price and technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candlestick chart with indicators\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles=('Price & Moving Averages', 'RSI', 'Volume'),\n",
    "    row_heights=[0.5, 0.25, 0.25]\n",
    ")\n",
    "\n",
    "# Candlestick\n",
    "fig.add_trace(\n",
    "    go.Candlestick(\n",
    "        x=df_features.index,\n",
    "        open=df_features['open'],\n",
    "        high=df_features['high'],\n",
    "        low=df_features['low'],\n",
    "        close=df_features['close'],\n",
    "        name='Price'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Moving averages\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_features.index, y=df_features['sma_7'], name='SMA 7', line=dict(color='orange')),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_features.index, y=df_features['sma_25'], name='SMA 25', line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# RSI\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_features.index, y=df_features['rsi'], name='RSI', line=dict(color='purple')),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=2, col=1)\n",
    "\n",
    "# Volume\n",
    "fig.add_trace(\n",
    "    go.Bar(x=df_features.index, y=df_features['volume'], name='Volume', marker_color='lightblue'),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{SYMBOL} - Technical Analysis',\n",
    "    height=800,\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd1375",
   "metadata": {},
   "source": [
    "## ü§ñ 5. Model Training\n",
    "\n",
    "Now let's train multiple machine learning models to predict price movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad64eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = StockPricePredictor()\n",
    "\n",
    "# Prepare data\n",
    "print(\"üìä Preparing training data...\")\n",
    "X, y, feature_names = predictor.prepare_data(df_features)\n",
    "\n",
    "if X is not None:\n",
    "    print(f\"‚úÖ Data prepared successfully\")\n",
    "    print(f\"   Features: {X.shape[1]}\")\n",
    "    print(f\"   Samples: {X.shape[0]}\")\n",
    "    print(f\"   Target distribution: {dict(pd.Series(y).value_counts())}\")\n",
    "    print()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Testing samples: {len(X_test)}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to prepare data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37240a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Random Forest...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_train_acc = accuracy_score(y_train, rf_model.predict(X_train))\n",
    "rf_test_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(f\"Train Accuracy: {rf_train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {rf_test_acc:.4f}\")\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Gradient Boosting...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_train_acc = accuracy_score(y_train, gb_model.predict(X_train))\n",
    "gb_test_acc = accuracy_score(y_test, gb_model.predict(X_test))\n",
    "\n",
    "print(f\"Train Accuracy: {gb_train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {gb_test_acc:.4f}\")\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, gb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b519f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training XGBoost...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_train_acc = accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "xgb_test_acc = accuracy_score(y_test, xgb_model.predict(X_test))\n",
    "\n",
    "print(f\"Train Accuracy: {xgb_train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {xgb_test_acc:.4f}\")\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052312d",
   "metadata": {},
   "source": [
    "## üìä 6. Model Comparison\n",
    "\n",
    "Let's compare the performance of all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Gradient Boosting', 'XGBoost'],\n",
    "    'Train Accuracy': [rf_train_acc, gb_train_acc, xgb_train_acc],\n",
    "    'Test Accuracy': [rf_test_acc, gb_test_acc, xgb_test_acc]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualize comparison\n",
    "fig = px.bar(\n",
    "    comparison_df,\n",
    "    x='Model',\n",
    "    y=['Train Accuracy', 'Test Accuracy'],\n",
    "    barmode='group',\n",
    "    title='Model Performance Comparison',\n",
    "    labels={'value': 'Accuracy', 'variable': 'Dataset'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} with {best_accuracy:.4f} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4418f",
   "metadata": {},
   "source": [
    "## üîç 7. Feature Importance\n",
    "\n",
    "Let's analyze which features are most important for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = rf_model\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_model = gb_model\n",
    "else:\n",
    "    best_model = xgb_model\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "display(feature_importance.head(10))\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    feature_importance.head(15),\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title=f'Top 15 Feature Importance - {best_model_name}',\n",
    "    labels={'Importance': 'Importance Score'}\n",
    ")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5e7f",
   "metadata": {},
   "source": [
    "## üéØ 8. Making Predictions\n",
    "\n",
    "Let's use our trained model to make predictions on recent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest data point\n",
    "latest_data = X[-1:]\n",
    "latest_features = pd.DataFrame(latest_data, columns=feature_names)\n",
    "\n",
    "print(\"Latest data point features:\")\n",
    "display(latest_features.T)\n",
    "\n",
    "# Make prediction\n",
    "prediction = best_model.predict(latest_data)[0]\n",
    "probabilities = best_model.predict_proba(latest_data)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION RESULT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Prediction: {'üìà UP (Price will increase)' if prediction == 1 else 'üìâ DOWN (Price will decrease)'}\")\n",
    "print(f\"Confidence: {max(probabilities):.2%}\")\n",
    "print()\n",
    "print(f\"Probability of DOWN: {probabilities[0]:.2%}\")\n",
    "print(f\"Probability of UP:   {probabilities[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c3a9c",
   "metadata": {},
   "source": [
    "## üí¨ 9. Sentiment Analysis\n",
    "\n",
    "Now let's analyze sentiment from financial news or social media text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1234dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"Bitcoin surges to new all-time high as institutional investors pile in!\",\n",
    "    \"Stock market crashes amid fears of recession and rising inflation.\",\n",
    "    \"Apple announces record-breaking quarterly earnings, beating expectations.\",\n",
    "    \"Tesla faces production delays and supply chain issues.\",\n",
    "    \"Cryptocurrency market shows strong recovery with positive momentum.\"\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SENTIMENT ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "results = []\n",
    "for i, text in enumerate(texts, 1):\n",
    "    result = sentiment_analyzer.analyze_text(text)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"{i}. Text: {text[:60]}...\")\n",
    "    print(f\"   Sentiment: {result['sentiment']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"   Scores: {result['scores']}\")\n",
    "    print()\n",
    "\n",
    "# Create sentiment distribution\n",
    "sentiment_df = pd.DataFrame(results)\n",
    "sentiment_counts = sentiment_df['sentiment'].value_counts()\n",
    "\n",
    "fig = px.pie(\n",
    "    values=sentiment_counts.values,\n",
    "    names=sentiment_counts.index,\n",
    "    title='Sentiment Distribution',\n",
    "    color_discrete_map={'positive': 'green', 'negative': 'red', 'neutral': 'gray'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9844107",
   "metadata": {},
   "source": [
    "## üìâ 10. Model Evaluation - Confusion Matrix\n",
    "\n",
    "Let's visualize the confusion matrix to understand model performance better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "y_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create heatmap\n",
    "fig = px.imshow(\n",
    "    cm,\n",
    "    labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "    x=['DOWN', 'UP'],\n",
    "    y=['DOWN', 'UP'],\n",
    "    title=f'Confusion Matrix - {best_model_name}',\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Calculate metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(f\"True Negatives:  {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives:  {tp}\")\n",
    "print()\n",
    "print(f\"Precision: {tp / (tp + fp):.4f}\")\n",
    "print(f\"Recall:    {tp / (tp + fn):.4f}\")\n",
    "print(f\"F1-Score:  {2 * tp / (2 * tp + fp + fn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80202ed",
   "metadata": {},
   "source": [
    "## üìù 11. Summary and Conclusions\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Data Collection**: Successfully collected and processed historical stock data\n",
    "2. **Feature Engineering**: Added 20+ technical indicators for better predictions\n",
    "3. **Model Training**: Trained and compared 3 different ML models\n",
    "4. **Best Model**: {best_model_name} achieved the highest accuracy\n",
    "5. **Predictions**: Model can predict price movements with reasonable confidence\n",
    "6. **Sentiment Analysis**: Successfully analyzed sentiment from financial text\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- üîÑ Retrain models periodically with fresh data\n",
    "- üìä Add more features (news sentiment, social media trends)\n",
    "- üéØ Fine-tune hyperparameters for better accuracy\n",
    "- üìà Implement real-time prediction pipeline\n",
    "- üöÄ Deploy as a web application (already done with Streamlit!)\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "‚ö†Ô∏è **Disclaimer**: This is for educational purposes only. Past performance does not guarantee future results. Always do your own research before making investment decisions.\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for using this notebook!** üéâ\n",
    "\n",
    "For the full web application, check out: https://mystockprediction.streamlit.app"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
